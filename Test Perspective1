import cv2
import numpy as np
import cv2.aruco as aruco

#define camera parameter
matrix_coefficients = [[1.25019753e+03, 0.00000000e+00, 8.31027626e+02,], 
                       [0.00000000e+00, 1.24629197e+03, 4.93761478e+02,],
                       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]
distortion_coefficients = [[ 0.22126322, -0.38411381, -0.01361529,  0.03204828, -0.06211731]]

markerLength = 0.2 #m
markerSeparation = 0.5 #m
size = (450,450)
#import image for analyze
frame = cv2.imread("test aruco.png")
src_corners1 = []
dst_corners = [(0, 0), (750, 0), (750, 100), (0, 100)] #test

#Part find id and markerpoint
frame = cv2.resize(frame, size)
gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Change grayscale
aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_50)  # Use 5x5 dictionary to find markers
parameters = aruco.DetectorParameters_create()  # Marker detection parameters
# lists of ids and the corners beloning to each id
corners, ids, rejected_img_points = aruco.detectMarkers(gray, aruco_dict,
                                                        parameters=parameters,
                                                        cameraMatrix=np.float32(matrix_coefficients),
                                                        distCoeff=np.float32(distortion_coefficients))
if np.all(ids is not None):  # If there are markers found by detector
    for i in range(0, len(ids)):  # Iterate in markers
        # Estimate pose of each marker and return the values rvec and tvec---different from camera coefficients
        rvec, tvec, markerPoints = aruco.estimatePoseSingleMarkers(corners[i], markerLength,
                                                                   np.float32(matrix_coefficients),
                                                                   np.float32(distortion_coefficients))

        (rvec - tvec).any()  # get rid of that nasty numpy value array error
        aruco.drawDetectedMarkers(frame, corners)  # Draw A square around the markers
        
        #setting scr_point to use in function cv2.getPerspectiveTransform
        markerpst = corners[i].copy()
        markerpst = corners[i].reshape((4,2))
        (topLeft, topRight, bottomRight, bottomLeft) = markerpst
        # convert each of the (x, y)-coordinate pairs to integers
        topRight = (int(topRight[0]), int(topRight[1]))
        bottomRight = (int(bottomRight[0]), int(bottomRight[1]))
        bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))
        topLeft = int((topLeft[0]), int(topLeft[1]))
        markerpst = ([[topLeft], [topRight], [bottomRight], [bottomLeft]])
        src_corners1.append(markerpst)
        #for set scr_point
        if ids[i] == 8:
            markerpst1 = topLeft    
        if ids[i] == 47:
            markerpst4 = bottomLeft
        if ids[i] == 18:
            markerpst3 = bottomRight
        if ids[i] == 14:
            markerpst2 = topRight
src_corners2 = [[markerpst1], [markerpst2], [markerpst3], [markerpst4]] #this array is src point to use in function cv2.getPerspectiveTransform to find matrix adjust

# create a black image with the same size of cam image
dstimg = frame.copy()
mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 19, 5)
cnt_pst = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
for i  in range(len(src_corners)):
    pst = np.array(src_corners[i])
    image = np.zeros(size)
    cv2.fillPoly(mask, pts = [pst], color =(255,255,255))
    cv2.imshow("test", mask)

#get Perspectivetransform
matrix_adjust = cv2.getPerspectiveTransform((src_corners2), (dst_corners))
result = cv2.warpPerspective(dstimg, matrix_adjust, (500, 600))
cv2.imshow("result", result)

cv2.waitKey(0)
cv2.destroyAllWindows()
